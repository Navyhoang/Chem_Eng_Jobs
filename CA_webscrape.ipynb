{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Webscrape for Data Related Jobs in Canada\n",
    "----\n",
    "4 queries were made into ca.Indeed.com to obtain job postings for (1) Chemical Engineer, (2) Process Engineer, (3) Process Design Engineer, (4) Clean Energy Engineer, (5) Renewable Energy Engineer, (6) Data Analyst Engineer, (7) Mettallurgical Engineer, (8) Metallurgy engineer. Data will be limited to the last 14 days. Due to large quantities of job postings, a limit of 70 pages were extracted (equaling around 1000 job posts) for each role. \n",
    "\n",
    "Job title index was also assigned to each job posting during the web scrape. For example, while scraping for Data Analyst roles, an index number of 1 was assigned to each posting. This will help for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install fake_useragent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencies\n",
    "from bs4 import BeautifulSoup as Soup\n",
    "import requests\n",
    "import pymongo\n",
    "import urllib, requests, re, pandas as pd\n",
    "from pprint import pprint\n",
    "import random\n",
    "from fake_useragent import UserAgent\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From here we generate a random user agent\n",
    "ua = UserAgent()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['181.129.183.19:53281', '125.27.251.87:58182', '103.90.145.196:8080', '154.72.204.122:8080', '110.232.86.52:53281', '103.242.15.37:55443', '124.41.240.126:31984', '51.81.82.175:80', '89.40.48.186:8080', '190.167.215.170:52479', '69.65.65.178:58389', '187.72.139.10:80', '78.111.97.179:3139', '139.99.102.114:80', '37.120.192.154:8080', '103.109.59.242:53281', '106.104.151.142:58198', '122.15.131.65:57873', '168.119.49.225:10007', '40.79.26.139:1080', '20.50.135.160:1080', '24.248.207.7:55443', '161.202.226.194:80', '41.217.219.53:31398', '36.84.99.192:3128', '60.246.7.4:8080', '41.65.174.66:8080', '142.93.147.210:3128', '87.140.8.148:8080', '51.75.147.41:3128', '68.183.221.156:42430', '35.182.149.39:3129', '159.89.121.54:8080', '118.175.207.180:40017', '207.144.111.230:8080', '109.74.66.102:3128', '81.182.0.87:8080', '92.115.102.133:55443', '128.14.178.94:3128', '45.235.110.66:53281', '139.255.11.147:8080', '128.14.163.94:3128', '167.172.191.249:46377', '167.172.109.12:44465', '167.71.239.213:8080', '139.99.105.5:80', '158.140.167.148:53281', '168.119.202.71:8080', '117.54.130.66:53281', '124.41.243.72:44716', '118.27.26.70:3128', '118.174.232.106:50491', '209.45.111.194:45729', '43.229.73.251:59648', '94.130.179.24:8009', '193.36.61.203:8000', '103.253.27.108:80', '157.230.103.189:46286', '118.172.201.80:61018', '195.239.178.110:48009', '103.215.177.231:80', '172.104.4.99:3128', '36.66.173.145:45685', '150.129.201.30:6666', '181.129.70.82:46752', '128.14.163.92:3128', '91.245.72.125:8080', '139.99.105.185:80', '95.216.9.69:2020', '65.184.156.234:52981', '113.53.83.212:44664', '82.223.3.52:8118', '104.238.81.186:56221', '62.23.15.92:3128', '208.80.28.208:8080', '27.116.51.115:8080', '1.20.103.248:52574', '35.214.193.155:3128', '182.52.90.43:33326', '14.63.228.217:80', '103.82.233.2:53281', '118.174.196.112:36314', '185.114.23.18:3128', '81.91.137.43:8080', '221.141.130.183:33741', '45.224.22.26:35090', '216.169.73.65:34679', '81.95.230.211:3128', '95.31.5.29:54651', '200.68.13.26:41283', '118.173.233.149:45160', '45.4.85.76:9991', '135.181.18.96:8080', '193.188.254.67:53281', '105.247.67.115:8080', '85.234.126.107:55555', '163.53.209.8:6666', '181.196.176.22:44577', '51.75.147.35:3128', '202.51.68.14:59175']\n"
     ]
    }
   ],
   "source": [
    "# Get a list of latest proxies from a free website\n",
    "res = requests.get('https://www.sslproxies.org/', headers={'User-Agent':'Mozilla/5.0'})\n",
    "soup = Soup(res.text,\"lxml\")\n",
    "\n",
    "proxy_list = []\n",
    "\n",
    "for items in soup.select(\"#proxylisttable tbody tr\"):\n",
    "    proxy_ip = ':'.join([item.text for item in items.select(\"td\")[:2]])\n",
    "    proxy_list.append(proxy_ip)\n",
    "\n",
    "print(proxy_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list job titles to be searched\n",
    "titles = [\"Process+EIT\",\n",
    "          \"Process+Engineer-in-training\",         \n",
    "          \"Junior+Process+Engineer\",\n",
    "          \"Junior+Chemical+Engineer\",\n",
    "          \"Junior+Project+Engineer\",\n",
    "          \"Junior+R&D+Engineer\",\n",
    "          \"Junior+Field+Production+Engineer\",\n",
    "          \"Junior+Reliability+Engineer\",\n",
    "          \"Junior+QA+Engineer\"\n",
    "          \"Junior+Water+Engineer\",\n",
    "          \"Junior+Data+Engineer\",\n",
    "          \"Junior+Sustainable+Energy+Engineer\",\n",
    "          \"Junior+Renewable+Energy+Engineer\",         \n",
    "          \"Junior+Mettallurgical+Engineer\"\n",
    "          ]\n",
    "\n",
    "# Create empty lists to collect information later\n",
    "job_title_list = []\n",
    "job_title_index = []\n",
    "company_list = []\n",
    "job_id_list = []\n",
    "location_list = []\n",
    "links_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create random parameters\n",
    "user_agent = ua.random\n",
    "header = {\"user-agent\": str(user_agent)}\n",
    "\n",
    "# Create random proxy list\n",
    "proxy = random.choice(proxy_list)\n",
    "proxy_protocol = {\n",
    "    \"http\"  : proxy,\n",
    "    \"https\" : proxy\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------\n",
      "Starting job search for:  Process+EIT\n",
      "Current page:  https://ca.indeed.com/jobs?q=Process+EIT&l=canada&sort=date&fromage=14&start=0\n",
      "Page number:  3\n",
      "Current page:  https://ca.indeed.com/jobs?q=Process+EIT&l=canada&sort=date&fromage=14&start=10\n",
      "Current page:  https://ca.indeed.com/jobs?q=Process+EIT&l=canada&sort=date&fromage=14&start=20\n",
      "Current page:  https://ca.indeed.com/jobs?q=Process+EIT&l=canada&sort=date&fromage=14&start=30\n",
      "---------------\n",
      "Starting job search for:  Process+Engineer-in-training\n",
      "Current page:  https://ca.indeed.com/jobs?q=Process+Engineer-in-training&l=canada&sort=date&fromage=14&start=0\n",
      "Page number:  1\n",
      "Current page:  https://ca.indeed.com/jobs?q=Process+Engineer-in-training&l=canada&sort=date&fromage=14&start=10\n",
      "---------------\n",
      "Starting job search for:  Junior+Process+Engineer\n",
      "Current page:  https://ca.indeed.com/jobs?q=Junior+Process+Engineer&l=canada&sort=date&fromage=14&start=0\n",
      "Page number:  1\n",
      "Current page:  https://ca.indeed.com/jobs?q=Junior+Process+Engineer&l=canada&sort=date&fromage=14&start=10\n",
      "---------------\n",
      "Starting job search for:  Junior+Chemical+Engineer\n",
      "Current page:  https://ca.indeed.com/jobs?q=Junior+Chemical+Engineer&l=canada&sort=date&fromage=14&start=0\n",
      "Page number:  1\n",
      "Current page:  https://ca.indeed.com/jobs?q=Junior+Chemical+Engineer&l=canada&sort=date&fromage=14&start=10\n",
      "---------------\n",
      "Starting job search for:  Junior+Project+Engineer\n",
      "Current page:  https://ca.indeed.com/jobs?q=Junior+Project+Engineer&l=canada&sort=date&fromage=14&start=0\n",
      "Page number:  1\n",
      "Current page:  https://ca.indeed.com/jobs?q=Junior+Project+Engineer&l=canada&sort=date&fromage=14&start=10\n",
      "---------------\n",
      "Starting job search for:  Junior+R&D+Engineer\n",
      "Current page:  https://ca.indeed.com/jobs?q=Junior+R&D+Engineer&l=canada&sort=date&fromage=14&start=0\n",
      "Page number:  2\n",
      "Current page:  https://ca.indeed.com/jobs?q=Junior+R&D+Engineer&l=canada&sort=date&fromage=14&start=10\n",
      "Current page:  https://ca.indeed.com/jobs?q=Junior+R&D+Engineer&l=canada&sort=date&fromage=14&start=20\n",
      "---------------\n",
      "Starting job search for:  Junior+Field+Production+Engineer\n",
      "Current page:  https://ca.indeed.com/jobs?q=Junior+Field+Production+Engineer&l=canada&sort=date&fromage=14&start=0\n",
      "Page number:  3\n",
      "Current page:  https://ca.indeed.com/jobs?q=Junior+Field+Production+Engineer&l=canada&sort=date&fromage=14&start=10\n",
      "Current page:  https://ca.indeed.com/jobs?q=Junior+Field+Production+Engineer&l=canada&sort=date&fromage=14&start=20\n",
      "Current page:  https://ca.indeed.com/jobs?q=Junior+Field+Production+Engineer&l=canada&sort=date&fromage=14&start=30\n",
      "---------------\n",
      "Starting job search for:  Junior+Reliability+Engineer\n",
      "Current page:  https://ca.indeed.com/jobs?q=Junior+Reliability+Engineer&l=canada&sort=date&fromage=14&start=0\n",
      "Page number:  5\n",
      "Current page:  https://ca.indeed.com/jobs?q=Junior+Reliability+Engineer&l=canada&sort=date&fromage=14&start=10\n",
      "Current page:  https://ca.indeed.com/jobs?q=Junior+Reliability+Engineer&l=canada&sort=date&fromage=14&start=20\n",
      "Current page:  https://ca.indeed.com/jobs?q=Junior+Reliability+Engineer&l=canada&sort=date&fromage=14&start=30\n",
      "Current page:  https://ca.indeed.com/jobs?q=Junior+Reliability+Engineer&l=canada&sort=date&fromage=14&start=40\n",
      "Current page:  https://ca.indeed.com/jobs?q=Junior+Reliability+Engineer&l=canada&sort=date&fromage=14&start=50\n",
      "---------------\n",
      "Starting job search for:  Junior+QA+EngineerJunior+Water+Engineer\n",
      "Current page:  https://ca.indeed.com/jobs?q=Junior+QA+EngineerJunior+Water+Engineer&l=canada&sort=date&fromage=14&start=0\n",
      "There is 0 result for this job title\n",
      "---------------\n",
      "---------------\n",
      "Starting job search for:  Junior+Data+Engineer\n",
      "Current page:  https://ca.indeed.com/jobs?q=Junior+Data+Engineer&l=canada&sort=date&fromage=14&start=0\n",
      "Page number:  12\n",
      "Current page:  https://ca.indeed.com/jobs?q=Junior+Data+Engineer&l=canada&sort=date&fromage=14&start=10\n",
      "Current page:  https://ca.indeed.com/jobs?q=Junior+Data+Engineer&l=canada&sort=date&fromage=14&start=20\n",
      "Current page:  https://ca.indeed.com/jobs?q=Junior+Data+Engineer&l=canada&sort=date&fromage=14&start=30\n",
      "Current page:  https://ca.indeed.com/jobs?q=Junior+Data+Engineer&l=canada&sort=date&fromage=14&start=40\n",
      "Current page:  https://ca.indeed.com/jobs?q=Junior+Data+Engineer&l=canada&sort=date&fromage=14&start=50\n",
      "Current page:  https://ca.indeed.com/jobs?q=Junior+Data+Engineer&l=canada&sort=date&fromage=14&start=60\n",
      "Current page:  https://ca.indeed.com/jobs?q=Junior+Data+Engineer&l=canada&sort=date&fromage=14&start=70\n",
      "Current page:  https://ca.indeed.com/jobs?q=Junior+Data+Engineer&l=canada&sort=date&fromage=14&start=80\n",
      "Current page:  https://ca.indeed.com/jobs?q=Junior+Data+Engineer&l=canada&sort=date&fromage=14&start=90\n",
      "---------------\n",
      "                A new user-agent was created:\n",
      "                Mozilla/5.0 (Macintosh; Intel Mac OS X 10_10_1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/37.0.2062.124 Safari/537.36\n",
      "----------------\n",
      "Current page:  https://ca.indeed.com/jobs?q=Junior+Data+Engineer&l=canada&sort=date&fromage=14&start=100\n",
      "Current page:  https://ca.indeed.com/jobs?q=Junior+Data+Engineer&l=canada&sort=date&fromage=14&start=110\n",
      "Current page:  https://ca.indeed.com/jobs?q=Junior+Data+Engineer&l=canada&sort=date&fromage=14&start=120\n",
      "---------------\n",
      "Starting job search for:  Junior+Sustainable+Energy+Engineer\n",
      "Current page:  https://ca.indeed.com/jobs?q=Junior+Sustainable+Energy+Engineer&l=canada&sort=date&fromage=14&start=0\n",
      "Page number:  1\n",
      "Current page:  https://ca.indeed.com/jobs?q=Junior+Sustainable+Energy+Engineer&l=canada&sort=date&fromage=14&start=10\n",
      "---------------\n",
      "Starting job search for:  Junior+Renewable+Energy+Engineer\n",
      "Current page:  https://ca.indeed.com/jobs?q=Junior+Renewable+Energy+Engineer&l=canada&sort=date&fromage=14&start=0\n",
      "Page number:  1\n",
      "Current page:  https://ca.indeed.com/jobs?q=Junior+Renewable+Energy+Engineer&l=canada&sort=date&fromage=14&start=10\n",
      "---------------\n",
      "Starting job search for:  Junior+Mettallurgical+Engineer\n",
      "Current page:  https://ca.indeed.com/jobs?q=Junior+Mettallurgical+Engineer&l=canada&sort=date&fromage=14&start=0\n",
      "There is 0 result for this job title\n",
      "---------------\n",
      "===================\n",
      "Scraping completed\n"
     ]
    }
   ],
   "source": [
    "# Country code \n",
    "country_code = \"ca\"\n",
    "country = \"canada\"\n",
    "days = \"14\"\n",
    "\n",
    "# Start the main web scraping\n",
    "for i, title in enumerate(titles):\n",
    "\n",
    "    print(\"---------------\")\n",
    "    print(\"Starting job search for: \", title)\n",
    "    # Reset page to 0\n",
    "    page = 0\n",
    "    counter = True\n",
    "\n",
    "    while counter == True:\n",
    "        \n",
    "        # search query for Data Analyst roles\n",
    "        url = f'https://{country_code}.indeed.com/jobs?q={title}&l={country}&sort=date&fromage={days}&start={page}'\n",
    "        print(\"Current page: \", url)\n",
    "\n",
    "        # Random time gap\n",
    "        time_gap = random.randrange(3, 7, 1)\n",
    "        time.sleep(time_gap)\n",
    "        \n",
    "        # Retrieve page with the requests module\n",
    "        response = requests.get(\n",
    "                            url,\n",
    "                            #proxies=proxy_protocol,\n",
    "                            headers=header\n",
    "                        )\n",
    "        \n",
    "        # Create BeautifulSoup object; parse with 'html.parser'\n",
    "        soup = Soup(response.text, 'lxml')\n",
    "           \n",
    "        # Retrieve the parent divs for all articles\n",
    "        results = soup.find_all('div', class_='result')\n",
    "\n",
    "\n",
    "        # For page one, calculate the page number by deviding job counts by 15 (each Indeed page has 15 postings)\n",
    "        if page == 0:\n",
    "            \n",
    "            try:\n",
    "            \n",
    "                job_count = soup.find('div', id='searchCountPages').text.strip()\n",
    "                job_count = job_count.replace(\",\", \"\")\n",
    "                job_count = int(job_count.split(\" \")[3])\n",
    "                page_count = round(job_count / 15, 0)\n",
    "                page_range = int(page_count)\n",
    "\n",
    "                if page_count == 0:\n",
    "                    page_count = 1\n",
    "                    page_range = int(page_count)\n",
    "                    \n",
    "                    \n",
    "                print(\"Page number: \", int(page_count))\n",
    "\n",
    "            except:\n",
    "                counter = False\n",
    "                print(\"There is 0 result for this job title\")\n",
    "                print(\"---------------\")\n",
    "\n",
    "        # Stop going to the next page when the last page was reached, 10 is because page goes as 10,20,30,...\n",
    "        elif page == page_range*10:\n",
    "            counter = False\n",
    "\n",
    "\n",
    "        # loop over results to get article data\n",
    "        for result in results:\n",
    "            \n",
    "            try:\n",
    "                # scrape the article header \n",
    "                job_title = result.find('a', class_='jobtitle').text.strip()\n",
    "\n",
    "                # give the current title an index for differentiation purpose later in analysys step\n",
    "                job_index = i + 1\n",
    "\n",
    "                # scrape information\n",
    "                company = result.find('span', class_='company').text.strip()\n",
    "                job_id = result.get('id')\n",
    "                location = result.find(class_='location').text \n",
    "#                 id_number = job_id.replace(\"_\", \" \")\n",
    "#                 id_number = str(id_number.split(\" \")[2])\n",
    "                link = f\"{url}&vjk={job_id}\"\n",
    "                \n",
    "                # append to the lists\n",
    "                job_title_list.append(job_title)\n",
    "                job_title_index.append(job_index)\n",
    "                company_list.append(company)\n",
    "                location_list.append(location)\n",
    "                job_id_list.append(job_id)\n",
    "                links_list.append(link)\n",
    "                \n",
    "            except:\n",
    "                pass\n",
    "\n",
    "        # Update page parameter by adding 10\n",
    "        page += 10\n",
    "\n",
    "        # Every 10 pages, get random UA\n",
    "        if page % 100 == 0:\n",
    "\n",
    "            user_agent = ua.random\n",
    "            header = {\"user-agent\": str(user_agent)}\n",
    "            print(f\"---------------\\n\\\n",
    "                A new user-agent was created:\\n\\\n",
    "                {user_agent}\\n----------------\")\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "print(\"===================\\nScraping completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\n",
    "                \"Job Title Index\" : job_title_index,    \n",
    "                \"Job ID\" : job_id_list,\n",
    "                \"Job Title\" : job_title_list, \n",
    "                \"Company Name\" : company_list, \n",
    "                \"Company Location\" : location_list,\n",
    "                \"Link\": links_list\n",
    "                    \n",
    "})\n",
    "\n",
    "\n",
    "df.to_csv('CA_chemengjobs.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
